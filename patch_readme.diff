diff --git a/README.md b/README.md
--- a/README.md
+++ b/README.md
@@ -1,23 +1,130 @@
-# Event-driven game backend demo (Outbox → Kafka)
-
-Mini-demo project: **Postgres Outbox pattern** → **Kafka** → **idempotent consumer** (dedup by `event_id`) → **read-model materialization** (via `recompute_game_read_model`).
-
-## Requirements
-- Python 3.11
-- Docker + docker compose
-
-## Quickstart (local)
-
-```bash
-docker compose up -d
-python -m venv .venv && source .venv/bin/activate  # Windows: .venv\Scripts\activate
-pip install -r requirements.txt
-export DATABASE_URL=postgresql://postgres:postgres@localhost:5432/bot_game_test  # Windows: $env:DATABASE_URL=...
-alembic upgrade head
-python outbox_publisher.py --check
-python outbox_publisher.py
-python consumer.py
-
-# open Kafka UI
-# http://localhost:8088
+# Outbox → Kafka → Consumer demo
+
+Короткий проект-демо: **Transactional Outbox** (PostgreSQL) → **Kafka** → **идемпотентный consumer**
+(dedup по `event_id`) → запись факта потребления в `consumed_events` (+ заготовка под read-model).
+
+## Что это показывает
+- надёжную публикацию событий из БД в Kafka (`outbox_publisher.py`);
+- идемпотентную обработку на стороне consumer (таблица `consumed_events`, `ON CONFLICT DO NOTHING`);
+- воспроизводимый сценарий запуска “с нуля” через Docker Compose.
+
+## Требования
+- Docker Desktop + Docker Compose v2
+- PowerShell (Windows) или любой shell
+
+## Быстрый старт (только Docker)
+
+```powershell
+# 1) инфраструктура
+docker compose up -d pg kafka kafka-ui
+
+# 2) миграции схемы
+docker compose run --rm migrator
+
+# 3) relay (publisher) + consumer
+docker compose up -d relay consumer
+
+docker compose ps
+```
+
+Kafka UI: `http://localhost:8088`
+
+## Проверка, что publisher видит БД и Kafka
+
+```powershell
+docker compose run --rm relay python outbox_publisher.py --check
+```
+
+## Сгенерировать демо-событие (вставка в outbox_events)
+
+В PowerShell безопаснее не мучиться с экранированием JSON, а собирать payload через `jsonb_build_object`
+и отправлять SQL через here-string в `psql`:
+
+```powershell
+$sql = @"
+INSERT INTO outbox_events
+  (id,event_type,aggregate_type,aggregate_id,payload,created_at,publish_attempts,last_error,published_at,idempotency_key,status)
+VALUES
+  (gen_random_uuid(),
+   'game.finished',
+   'game',
+   '11111111-1111-1111-1111-111111111111',
+   jsonb_build_object('game_id','11111111-1111-1111-1111-111111111111','chat_id',-5056821738),
+   now(),0,NULL,NULL,concat('demo-', gen_random_uuid()),'new');
+"@
+
+$sql | docker compose exec -T pg psql -U postgres -d bot_game_test -v ON_ERROR_STOP=1
+```
+
+## Убедиться, что событие ушло в Kafka
+
+```powershell
+docker exec -it bot_game_kafka /opt/kafka/bin/kafka-console-consumer.sh `
+  --bootstrap-server kafka:19092 `
+  --topic game-events `
+  --from-beginning `
+  --timeout-ms 5000
+```
+
+## Убедиться, что consumer отметил событие в БД
+
+```powershell
+$sql = @"
+SELECT event_id, event_type, topic, "partition", kafka_offset, consumed_at
+FROM consumed_events
+ORDER BY consumed_at DESC
+LIMIT 10;
+"@
+
+$sql | docker compose exec -T pg psql -U postgres -d bot_game_test -v ON_ERROR_STOP=1
+```
+
+## Replay
+
+Два уровня “повтора”:
+
+1) **Kafka replay** — запускаем consumer с новым `KAFKA_CONSUMER_GROUP`, чтобы прочитать топик с начала.
+
+2) **Dedup replay** — consumer не обработает повторно `event_id`, который уже есть в `consumed_events`.
+   Для повторной обработки конкретного события удаляем его строку из `consumed_events`.
+
+```powershell
+# (1) новый group id → чтение с начала топика
+$env:KAFKA_CONSUMER_GROUP = "replay-$([guid]::NewGuid())"
+docker compose up -d --force-recreate consumer
+
+# (2) заставить consumer обработать конкретный event_id снова
+$eid = "098b6bc4-ae94-45ec-b71a-f0a7b77e7c50"  # подставь свой event_id
+$sql = @"
+DELETE FROM consumed_events
+WHERE event_id = '$eid'::uuid;
+"@
+$sql | docker compose exec -T pg psql -U postgres -d bot_game_test -v ON_ERROR_STOP=1
+
+docker compose up -d --force-recreate consumer
+```
+
+## Остановить и очистить окружение
+
+```powershell
+docker compose down -v
+```